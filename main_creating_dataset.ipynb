{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon as MatplotlibPolygon\n",
    "from shapely import wkt\n",
    "import shapely\n",
    "import shapely.geometry as sg\n",
    "from shapely.geometry import Polygon, LineString, Point, MultiPoint\n",
    "import networkx as nx\n",
    "import geopandas as gp\n",
    "from shapely.ops import nearest_points \n",
    "from typing import Dict, List, Tuple, Union\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# from Plan import Plan\n",
    "from RoomColours import roomColours\n",
    "from MarkovChainClass import *\n",
    "from read_historic_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SDDS plan data as dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_from_file(file_path):\n",
    "    \"\"\" dataset composed in read_plans_csv.ipynb\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data_dict = pickle.load(file)\n",
    "    return data_dict\n",
    "\n",
    "plans = load_dict_from_file('Plans.pickle')\n",
    "plan_ids = load_dict_from_file('plan_ids.pickle')\n",
    "apartment_ids = load_dict_from_file('apartment_ids.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform MC simulation on decomposition graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[426.45, 362.43, 366.39, 145.71]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Monte Carlo Simulation of decomposition graph used to label floor plan pre-evacuation times\"\"\"\n",
    "\n",
    "pre_evac_time_per_start = []\n",
    "behaviour_class = behaviour_in_fire_markov_chain(10000, node_attributes = optimal_node_attributes)\n",
    "\n",
    "for i in Start_nodes:\n",
    "    total_time_i = round(behaviour_class.simulate_markov_chain(i, 10000), 2)\n",
    "    pre_evac_time_per_start.append(total_time_i)\n",
    "\n",
    "\n",
    "print(pre_evac_time_per_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create class to analyse plan geometry and adjacencies in terms of fire safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plan:\n",
    "    \"\"\" Class used to find plan rooms, adjacencies (with / without door) , evacuation times (Tp, Te) and create Graph (G = {N,E}) for predicting risk in a given floor plan\"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            Plan_id: int, \n",
    "            Apartment_id: str, \n",
    "            plans: dict,\n",
    "            mrkv_chain_behaviours: behaviour_in_fire_markov_chain,\n",
    "            room_of_origin_weights: dict\n",
    "    ):\n",
    "        \n",
    "        ## identification of plan\n",
    "        self.plans = plans\n",
    "        self.plan_id = Plan_id\n",
    "        self.apartment_id = Apartment_id\n",
    "\n",
    "        ## rooms / nodes\n",
    "        self.rooms = self.__get_rooms()\n",
    "        self.room_attributes = self.__get_room_attributes()\n",
    "        self.doors, self.door_widths, self.entrance_door  = self.__get_doors()\n",
    "\n",
    "        ## walls\n",
    "        self.walls = self.__get_walls()\n",
    "\n",
    "        ## distances between rooms and adjacency lists\n",
    "        self.connections_without_doors = self.__get_room_room_connections()\n",
    "        self.connections_with_doors, self.door_widths = self.__get_room_door_room_connections()\n",
    "        self.entrance_connection, self.entrance_door_centre = self.__get_entrance_connection()\n",
    "        self.edges_with_weights, self.edge_door_widths = self.__get_room_adjacencies()\n",
    "        self.edge_midpoints = self.__get_edge_midpoints()\n",
    "        self.edge_attributes = self.__get_edge_attributes()\n",
    "\n",
    "        ## get centres of nodes\n",
    "        self.room_centers = self.__get_room_centres()\n",
    "\n",
    "        ## markov chain fire emergency behaviour\n",
    "        self.mrk_chain = mrkv_chain_behaviours\n",
    "\n",
    "        ## room of origin likelihood\n",
    "        self.room_of_origin_weights = room_of_origin_weights\n",
    "        \n",
    "        ## graph\n",
    "        self.graph = self.__make_graph()\n",
    "\n",
    "    def show_plan_apartment(self) -> None:\n",
    "        \"\"\" Displays the plan of the one apartment specified in class initiation \"\"\"\n",
    "\n",
    "        #    Extract plan ID and apartment ID\n",
    "        plan_id = self.plan_id\n",
    "        apartment_id = self.apartment_id\n",
    "\n",
    "        # Load geometry from plans\n",
    "        geo = shapely.wkt.loads(self.plans[plan_id][apartment_id]['geometries_dict'])\n",
    "        \n",
    "        # Plot the geometry\n",
    "        plt.figure()\n",
    "        p = gp.GeoSeries(geo)\n",
    "\n",
    "        p.plot(color=self.__give_colours())\n",
    "\n",
    "\n",
    "        \n",
    "        # Set title\n",
    "        plt.suptitle('Plan: ' + str(plan_id) + ', ' + 'apartment: ' + apartment_id)\n",
    "        \n",
    "        # Show plot\n",
    "        plt.show()\n",
    "\n",
    "    def show_plan(self) -> None:\n",
    "        \"\"\" Displays the plan of the whole floor in which the plan is in\"\"\"\n",
    "        \n",
    "        # Extract plan ID\n",
    "        plan_id = self.plan_id\n",
    "\n",
    "        # Initialize lists for geometry and colors\n",
    "        _geo = []\n",
    "        colours = []\n",
    "\n",
    "        # Iterate over apartment IDs for the given plan\n",
    "        for apartment_id in apartment_ids[plan_id]:\n",
    "            # Create a Plan object for the current apartment\n",
    "            plan = Plan(plan_id, apartment_id, plans, self.mrk_chain, self.room_of_origin_weights)\n",
    "            \n",
    "            # Append colors from the current apartment to the colors list\n",
    "            colours += plan.__give_colours()\n",
    "            \n",
    "            # Append geometry from the current apartment to the _geo list\n",
    "            _geo.append(shapely.wkt.loads(self.plans[plan_id][apartment_id]['geometries_dict']))\n",
    "\n",
    "        # Flatten the list of geometries_dict\n",
    "        geo = [polygon for row in _geo for polygon in row]\n",
    "\n",
    "        # Plot the geometries_dict\n",
    "        p = gp.GeoSeries(geo)\n",
    "        p.plot(color=colours)\n",
    "        \n",
    "        # Set title\n",
    "        plt.suptitle('Plan: ' + str(plan_id))\n",
    "        \n",
    "        # Show plot\n",
    "        plt.show()\n",
    "\n",
    "    def show_graph(self) -> None:\n",
    "        \"\"\"Displays the graph representation of the floor plan\"\"\"\n",
    "\n",
    "        G = self.graph\n",
    "        pos = self.room_centers\n",
    "        edge_labels = {(node1, node2): str(distance) for node1, node2, distance in self.edges_with_weights}\n",
    "\n",
    "        plt.figure(figsize=(10, 10))  # Initiate graph figure\n",
    "\n",
    "        # Draw nodes\n",
    "        node_colors = [G.nodes[node]['colour'] for node in G.nodes()]\n",
    "        node_sizes = [((G.nodes[node]['room_area'] + 10) * 200) for node in G.nodes()]\n",
    "        nx.draw(G, \n",
    "                pos=pos, \n",
    "                with_labels=False,\n",
    "                node_color=node_colors, \n",
    "                node_size=node_sizes, \n",
    "                alpha=0.3, \n",
    "                linewidths=5\n",
    "            )\n",
    "\n",
    "        # Draw edges\n",
    "        nx.draw_networkx_edges(G, \n",
    "                            pos, \n",
    "                            width=1, \n",
    "                            edge_color='#AAAE7F'\n",
    "                        )\n",
    "\n",
    "        # Draw node labels\n",
    "        node_labels = {\n",
    "            node: (f\"{G.nodes[node]['node_index']}: {G.nodes[node]['room_type']}\\n\"\n",
    "                f\"exit_dis: {G.nodes[node]['distance_to_exit']}\\n\"\n",
    "                f\"area: {G.nodes[node]['room_area']}\\n\"\n",
    "                f\"Tp: {G.nodes[node]['time_pre_evac']}\\n\"\n",
    "                f\"Te: {G.nodes[node]['time_evac']}\\n\"\n",
    "                f\"b_c: {round(G.nodes[node]['betweenness_centrality'],2)}\\n\"\n",
    "                f\"c_c: {round(G.nodes[node]['closeness_centrality'],2)}\")\n",
    "            for node in G.nodes()\n",
    "        }\n",
    "        nx.draw_networkx_labels(G, \n",
    "                                pos=pos, \n",
    "                                labels=node_labels, \n",
    "                                font_size=9, \n",
    "                                font_weight='normal',\n",
    "                                horizontalalignment='center'\n",
    "                            )\n",
    "\n",
    "        # Draw edge labels\n",
    "        nx.draw_networkx_edge_labels(G, \n",
    "                                    pos, \n",
    "                                    edge_labels=edge_labels, \n",
    "                                    font_weight='bold', \n",
    "                                    alpha=0.35\n",
    "                                )\n",
    "\n",
    "        plt.show()  # Show graph\n",
    "\n",
    "    def __give_colours(self) -> List[str]:\n",
    "        \"\"\" Returns the list of room colours for all rooms in the plan, according to RoomColours.py\"\"\"\n",
    "\n",
    "        # Extract plan ID and apartment ID\n",
    "        plan_id = self.plan_id\n",
    "        apartment_id = self.apartment_id\n",
    "\n",
    "        # Get subtypes for the given plan and apartment\n",
    "        subtypes = self.plans[plan_id][apartment_id]['sub_type_dict']\n",
    "\n",
    "        # Map subtypes to colors\n",
    "        colours = [roomColours[x] for x in subtypes]\n",
    "\n",
    "        return colours\n",
    "\n",
    "    def __get_rooms(self) -> List[Polygon]:\n",
    "        \"\"\" Returns all rooms in the plans as List of polygons \"\"\"\n",
    "\n",
    "        # Extract plan ID and apartment ID\n",
    "        plan_id = self.plan_id\n",
    "        apartment_id = self.apartment_id\n",
    "\n",
    "        # Fetch geometries_dict and types of apartment components from self.plans dictionary\n",
    "        component_geometry = self.plans[plan_id][apartment_id]['geometries_dict']\n",
    "        types = self.plans[plan_id][apartment_id]['types_dict']\n",
    "        sub_types = self.plans[plan_id][apartment_id]['sub_type_dict']\n",
    "\n",
    "        # Extract room shapes excluding shafts\n",
    "        rooms = [component_geometry[i] for i, x in enumerate(types) if types[i] == 'area' and sub_types[i] != 'SHAFT']\n",
    "        \n",
    "        # Convert WKT (Well-Known Text) format to Shapely geometries_dict for visualization and analysis\n",
    "        rooms = [shapely.wkt.loads(room) for room in rooms]\n",
    "        \n",
    "        return rooms\n",
    "    \n",
    "    def __get_room_attributes(self) -> Dict[int, Dict]:\n",
    "        \"\"\" Make room attributes dictionary => {node_id : {attributes}, node_id: {attributes}} \"\"\"\n",
    "\n",
    "        # Extract plan ID and apartment ID\n",
    "        plan_id = self.plan_id\n",
    "        apartment_id = self.apartment_id\n",
    "\n",
    "        # Extract component information from the floor plan\n",
    "        types = self.plans[plan_id][apartment_id]['types_dict']\n",
    "        sub_types = self.plans[plan_id][apartment_id]['sub_type_dict']\n",
    "        area_ids = self.plans[plan_id][apartment_id]['area_ids_dict']\n",
    "        max_distances_to_entrance = self.plans[plan_id][apartment_id]['distance_to_exit_dict']\n",
    "\n",
    "        # Extract room types excluding shafts\n",
    "        room_types = [sub_types[i] for i, x in enumerate(types) if types[i] == 'area' and sub_types[i] != 'SHAFT']\n",
    "        room_indices = list(range(len(room_types)))\n",
    "\n",
    "        # Extract room area IDs\n",
    "        room_area_ids = [area_ids[i] for i, x in enumerate(sub_types) if x != 'SHAFT']\n",
    "\n",
    "        # Extract room areas\n",
    "        room_areas = [round(room.area, 2) for room in self.rooms]\n",
    "\n",
    "        # Initialize room attributes dictionary\n",
    "        room_attributes = {}\n",
    "\n",
    "        # Populate room attributes\n",
    "        for i, idx in enumerate(room_indices):\n",
    "            room_attributes[idx] = {\n",
    "                'room_type': room_types[i],\n",
    "                'room_area_id': room_area_ids[i],\n",
    "                'distance_to_exit': max_distances_to_entrance[i],\n",
    "                'room_area': room_areas[i]\n",
    "            }\n",
    "\n",
    "        # Add entrance door properties\n",
    "        entrance_door_area_ids = [area_ids[i] for i, x in enumerate(sub_types) if x == 'ENTRANCE_DOOR']\n",
    "        entrance_door_idx = room_indices[-1] + 1\n",
    "        room_attributes[entrance_door_idx] = {\n",
    "            'room_type': 'ENTRANCE_DOOR',\n",
    "            'room_area_id': entrance_door_area_ids[0],\n",
    "            'distance_to_exit': 0,\n",
    "            'room_area': 0\n",
    "        }\n",
    "\n",
    "        return room_attributes\n",
    "\n",
    "    def __get_room_centres(self) -> Dict[int, Tuple[float, float]]:\n",
    "        \"\"\" Returns a dictionary of key : value as node_id: centroid\"\"\"\n",
    "        \n",
    "        # Extract rooms and entrance door\n",
    "        rooms = self.rooms\n",
    "        entrance_door_centre = self.entrance_door_centre\n",
    "        \n",
    "        # Initialize list of room indices\n",
    "        room_indices = list(range(len(rooms)))\n",
    "\n",
    "        # Add index for the entrance door\n",
    "        room_indices.append(len(rooms))\n",
    "\n",
    "        # Compute centroids of rooms and entrance door\n",
    "        centroids_pts = [shape.centroid for shape in rooms]\n",
    "        centroids_pts.append(entrance_door_centre)\n",
    "\n",
    "        # Create dictionary mapping indices to centroid coordinates\n",
    "        centroids_coords_dict = {\n",
    "            i: (round(point.x, 2), round(point.y, 2)) \n",
    "            for i, point in zip(room_indices, centroids_pts)\n",
    "        }\n",
    "        \n",
    "        return centroids_coords_dict\n",
    "\n",
    "    def __get_doors(self) -> Tuple[List[Polygon], Dict, Polygon]:\n",
    "        \"\"\" Returns a list of all doors, including the entrance door, as a list of polygons\"\"\"\n",
    "\n",
    "        # Extract plan ID and apartment ID   \n",
    "        plan_id = self.plan_id\n",
    "        apartment_id = self.apartment_id\n",
    "\n",
    "        # Extract component geometries_dict and subtypes\n",
    "        components = self.plans[plan_id][apartment_id]['geometries_dict']\n",
    "        sub_type_dict = self.plans[plan_id][apartment_id]['sub_type_dict']\n",
    "\n",
    "        # Extract door geometries_dict and entrance door geometry\n",
    "        doors = [components[i] for i, subtype in enumerate(sub_type_dict) if subtype in ['DOOR', 'ENTRANCE_DOOR']]\n",
    "        entrance_door = [components[i] for i, x in enumerate(sub_type_dict) if sub_type_dict[i] == 'ENTRANCE_DOOR' ]\n",
    "\n",
    "        # Convert geometries_dict from WKT to Shapely polygons\n",
    "        doors = shapely.wkt.loads(doors)\n",
    "        entrance_door = shapely.wkt.loads(entrance_door)[0]\n",
    "\n",
    "        def get_door_widths(doors):\n",
    "            \"\"\" Returns a list of door widths for each apartment, same indexing as self.doors\"\"\"\n",
    "\n",
    "            ## initialise door widths list\n",
    "            door_widths = []\n",
    "\n",
    "\n",
    "            for door in doors:\n",
    "                # Get the bounding box\n",
    "                minx, miny, maxx, maxy = door.bounds\n",
    "\n",
    "                # Calculate width and length\n",
    "                width = maxx - minx\n",
    "                length = maxy - miny\n",
    "\n",
    "                # Return the smallest of the two\n",
    "                door_width = max(width, length)\n",
    "                door_widths.append(door_width)\n",
    "\n",
    "            ## normalise door widths, so that connections without doors have weight of 1.0.\n",
    "            def normalize_list(values, min_value=0.75, max_value=0.1):\n",
    "                min_val = min(values)\n",
    "                max_val = max(values)\n",
    "\n",
    "                normalized_values = [0.1 for v in values]\n",
    "\n",
    "                for i, v in enumerate(values):\n",
    "                    if (max_val - min_val) == 0:\n",
    "                        normalized_values[i] = 0.05\n",
    "                    else:\n",
    "                        normalized_values[i] = round( ((v - min_val) / (max_val - min_val) * (max_value - min_value) + min_value), 2) \n",
    "                        \n",
    "                return normalized_values\n",
    "            \n",
    "            if len(door_widths) == 1:\n",
    "                width = door_widths[0]\n",
    "                if width > 0.75:\n",
    "                    normalised_door_widths = 0.0\n",
    "                else:\n",
    "                    normalised_door_widths = 0.75 / width\n",
    "            normalised_door_widths = normalize_list(door_widths)\n",
    "\n",
    "            return normalised_door_widths\n",
    "        \n",
    "        door_widths = get_door_widths(doors)\n",
    "        door_widths = {key: value for key, value in zip([i for i in range(len(doors))], door_widths)}\n",
    "\n",
    "        return doors, door_widths, entrance_door\n",
    "    \n",
    "    def __get_walls(self) -> List[Polygon]:\n",
    "        \"\"\" Returns all wall shapes in the plan as a list of polygons\"\"\"\n",
    "\n",
    "        # Extract plan ID and apartment ID\n",
    "        plan_id = self.plan_id\n",
    "        apartment_id = self.apartment_id\n",
    "\n",
    "        # Extract component geometries_dict and subtypes\n",
    "        components = self.plans[plan_id][apartment_id]['geometries_dict']\n",
    "        component_subtypes = self.plans[plan_id][apartment_id]['sub_type_dict']\n",
    "\n",
    "        # Extract wall geometries_dict\n",
    "        walls = [components[i] for i, subtype in enumerate(component_subtypes) if subtype == 'WALL']\n",
    "\n",
    "        # Convert geometries_dict from WKT to Shapely polygons\n",
    "        walls = [shapely.wkt.loads(wall) for wall in walls]\n",
    "\n",
    "        return walls\n",
    "\n",
    "    def __get_room_room_connections(self) -> Dict[Tuple[int, int], float]:\n",
    "        connection_distances = {}\n",
    "        connections_set = set()  # Adjacency matrix of rooms\n",
    "\n",
    "        # Iterate over rooms\n",
    "        for from_index, from_room in enumerate(self.rooms):\n",
    "            # Check connections to neighboring rooms without doors (open plan)\n",
    "            for to_index, to_room in enumerate(self.rooms):\n",
    "                if from_index == to_index:\n",
    "                    continue\n",
    "\n",
    "                # Find nearest points between rooms\n",
    "                roomToRoom_nearestPts = nearest_points(from_room, to_room)\n",
    "                roomToRoom_distance = round(roomToRoom_nearestPts[0].distance(roomToRoom_nearestPts[1]), 2)\n",
    "\n",
    "                if roomToRoom_distance < 0.07:\n",
    "                    # Sort connection, turn to tuple and add to set to prevent duplicate connections\n",
    "                    connection = tuple(sorted([from_index, to_index]))\n",
    "                    connections_set.add(connection)\n",
    "\n",
    "                    # Calculate mean connection distance (edge weight) and add to connection_distances\n",
    "                    pt_current_centre = from_room.centroid\n",
    "                    pt_neighbour_centre = to_room.centroid\n",
    "                    pt_connection = Point((pt_current_centre.x + pt_neighbour_centre.x) / 2,\n",
    "                                        (pt_neighbour_centre.y + pt_current_centre.y) / 2)\n",
    "                    line_connection_walk = LineString([pt_current_centre, pt_connection, pt_neighbour_centre])\n",
    "                    length_connection_walk = line_connection_walk.length\n",
    "                    connection_distances[connection] = round(length_connection_walk, 2)\n",
    "\n",
    "        return connection_distances\n",
    "    \n",
    "    def __get_room_door_room_connections(self) -> Tuple[Dict, Dict]:\n",
    "        rooms = self.rooms\n",
    "        doors = self.doors\n",
    "        connections_set = set()\n",
    "        connection_distances = {}\n",
    "        door_widths = {}\n",
    "\n",
    "        for door_index, door in enumerate(doors):\n",
    "            # make a connection (pair of rooms) for every door\n",
    "            connection = []\n",
    "            for room_index, room in enumerate(rooms):\n",
    "                doorToRoom_nearestPts = nearest_points(door, room)\n",
    "                doorToRoom_distance = round(doorToRoom_nearestPts[0].distance(doorToRoom_nearestPts[1]), 2)\n",
    "                if doorToRoom_distance == 0.0:\n",
    "                    connection.append(room_index)\n",
    "            # turn list into tuple and add to set to prevent adding duplicates\n",
    "            if len(connection) <= 1:\n",
    "                continue\n",
    "\n",
    "            # sort connection, turn to tuple and add to set to prevent duplicate connections\n",
    "            connection.sort()\n",
    "            connection = tuple(connection)\n",
    "            connections_set.add(connection)\n",
    "\n",
    "            ## add door index to dictionary for adding it as an edge attribute in self.make_graph()\n",
    "            door_widths[connection] = self.door_widths[door_index]\n",
    "\n",
    "            # calculate and add mean connection distance (edge weight) to connection distances\n",
    "            from_room = rooms[connection[0]]\n",
    "            to_room = rooms[connection[1]]\n",
    "\n",
    "            pt_current_centre = from_room.centroid\n",
    "            pt_neighbour_centre = to_room.centroid\n",
    "            pt_door_centre = door.centroid\n",
    "            line_connection_walk = LineString([pt_current_centre, pt_door_centre, pt_neighbour_centre])\n",
    "            length_connection_walk = line_connection_walk.length\n",
    "            connection_distances[connection] = round(length_connection_walk, 2)\n",
    "\n",
    "        return connection_distances, door_widths\n",
    "\n",
    "    def __get_entrance_connection(self) -> Tuple[Dict, Tuple[float, float]]:\n",
    "        # Extract necessary attributes\n",
    "        entrance_door = self.entrance_door\n",
    "        entrance_door_centre = entrance_door.centroid\n",
    "        rooms = self.rooms\n",
    "        entrance_door_node_id = len(rooms)\n",
    "        \n",
    "        # Initialize variables\n",
    "        connections_set = set()\n",
    "        connection_dict = {}\n",
    "\n",
    "        # Iterate over each room to compute connections with the entrance door\n",
    "        for i, room in enumerate(rooms):\n",
    "            # Compute distance between nearest points of the door and the current room\n",
    "            e_door_nearest_pts = nearest_points(entrance_door, room)\n",
    "            distance = round(e_door_nearest_pts[0].distance(e_door_nearest_pts[1]), 2)\n",
    "\n",
    "            # If the distance is 0, the door is adjacent to the room\n",
    "            if distance == 0.0:\n",
    "                # Create a connection between the entrance door and the room\n",
    "                connection = [entrance_door_node_id, i]\n",
    "                \n",
    "                # Compute connection weight (distance between the centre of the door and the centre of the room)\n",
    "                connection_distance = self.room_attributes[i]['distance_to_exit']\n",
    "                if not 0 <= connection_distance <= 100:\n",
    "                    connection_distance = round(entrance_door.centroid.distance(room.centroid), 2)\n",
    "                # connection_distance = round(entrance_door_centre.distance(room.centroid), 2)\n",
    "                \n",
    "                # Sort connection and convert to tuple\n",
    "                connection.sort()\n",
    "                connection = tuple(connection)\n",
    "                \n",
    "                # Add connection to the set to prevent duplicates\n",
    "                connections_set.add(connection)\n",
    "                \n",
    "                # Convert the set to a list and extract the connection tuple\n",
    "                connections = [tup for tup in connections_set]\n",
    "                connections = connections[0]\n",
    "                \n",
    "                # Add connection and its distance to the connection dictionary\n",
    "                connection_dict[connections] = connection_distance\n",
    "                    \n",
    "        return connection_dict, entrance_door_centre\n",
    "\n",
    "    def __make_graph(self) -> nx.Graph:\n",
    "        \"\"\" Constructs a nx.Graph component from Nodes, Edges, Node attributes and Edge Attributes\"\"\"\n",
    "\n",
    "        # Initialize an empty graph\n",
    "        G = nx.Graph()\n",
    "\n",
    "        # Add edges with weights and edge attributes\n",
    "        G.add_weighted_edges_from(self.edges_with_weights)\n",
    "        nx.set_edge_attributes(G, self.edge_attributes, 'attributes')\n",
    "\n",
    "        # Get shortest paths to exit\n",
    "        shortest_paths = self.__get_shortest_paths_to_exit(G)\n",
    "\n",
    "        Tp, Te = self.__get_exit_times()\n",
    "\n",
    "        # Add nodes and attributes\n",
    "        for i in G.nodes:\n",
    "            # Extract room attributes\n",
    "            room_type = self.room_attributes[i]['room_type']\n",
    "            distance_to_exit = self.room_attributes[i]['distance_to_exit']\n",
    "            node_area = self.room_attributes[i]['room_area']\n",
    "            time_pre_evac = Tp[i]\n",
    "            time_evac = Te[i]\n",
    " \n",
    "            # Correct distance to exit if invalid\n",
    "            if not 0 <= distance_to_exit <= 100:\n",
    "                distance_to_exit = shortest_paths[i]\n",
    "\n",
    "            if time_evac < 0.01:\n",
    "                time_evac = round(distance_to_exit / 0.7, 2)\n",
    "\n",
    "            # Get node color\n",
    "            node_color = roomColours[room_type]\n",
    "\n",
    "            # Add node to graph\n",
    "            G.add_node(\n",
    "                i, \n",
    "                colour=node_color, \n",
    "                room_type=room_type, \n",
    "                distance_to_exit=distance_to_exit, \n",
    "                node_index=i, \n",
    "                room_area=node_area,\n",
    "                time_pre_evac= time_pre_evac,\n",
    "                time_evac = time_evac\n",
    "            )\n",
    "            \n",
    "\n",
    "        # Add betweenness centrality attribute to nodes\n",
    "        betweenness_centrality = nx.betweenness_centrality(G)\n",
    "        nx.set_node_attributes(G, betweenness_centrality, 'betweenness_centrality')\n",
    "\n",
    "        # Add closeness centrality to nodes\n",
    "        closeness_centrality = nx.closeness_centrality(G)\n",
    "        nx.set_node_attributes(G, closeness_centrality, 'closeness_centrality')\n",
    "        \n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def __get_room_adjacencies(self) -> List[Tuple[int, int, float]]:\n",
    "\n",
    "        # Get node indices for rooms and entrance connection\n",
    "        node_indices = [i for i in range(len(self.rooms))]\n",
    "        node_indices += self.entrance_connection\n",
    "\n",
    "        # Retrieve room-door-room adjacencies, room-room adjacencies, and entrance-door adjacency\n",
    "        room_door_room_adjacencies = self.connections_with_doors\n",
    "        room_room_adjacencies = self.connections_without_doors\n",
    "        entrance_door_adjacency = self.entrance_connection\n",
    "\n",
    "        # Combine all adjacency information into a single dictionary\n",
    "        edges = {}\n",
    "        edges.update(room_door_room_adjacencies)\n",
    "        edges.update(room_room_adjacencies)\n",
    "        edges.update(entrance_door_adjacency)\n",
    "\n",
    "        ## create door_width dictionary\n",
    "        door_widths = {}\n",
    "        for edge in list(edges.keys()):\n",
    "            if edge in self.connections_with_doors.keys():\n",
    "                ## room connections with doors are further weighted by the normalised value of the inverse of the door widths (larger door -> smaller weight, smaller door -> bigger weight)\n",
    "                door_widths[edge] = self.door_widths[edge]\n",
    "            else:\n",
    "                ## room connections without doors are further weighted by 0.0, (preferable connection)\n",
    "                door_widths[edge] = 0.0\n",
    "\n",
    "        # Convert dictionary entries into a list of tuples with node indices and edge weights\n",
    "        edges_and_weights = [(a[0], a[1], v) for a, v in edges.items()]\n",
    "\n",
    "        return edges_and_weights, door_widths\n",
    "\n",
    "    def __get_edge_attributes(self) -> Dict:\n",
    "        edges_with_weights = self.edges_with_weights\n",
    "        room_types = self.room_attributes\n",
    "        edge_attributes = {}\n",
    "\n",
    "        # Iterate over each edge and extract attributes\n",
    "        for edge in edges_with_weights:\n",
    "            # Extract room types of nodes connected by the edge\n",
    "            node1_type = room_types[edge[0]]['room_type']\n",
    "            node2_type = room_types[edge[1]]['room_type']\n",
    "\n",
    "            # Store edge attributes with node types\n",
    "            edge_attributes[(edge[0], edge[1])] = {\n",
    "                'edge_node_types': (node1_type, node2_type), \n",
    "                'edge_opening_weight': self.edge_door_widths[(edge[0], edge[1])]\n",
    "            }\n",
    "\n",
    "            ## add door width to edge attribute\n",
    "    \n",
    "\n",
    "        return edge_attributes\n",
    "\n",
    "    def __get_edge_midpoints(self) -> Dict:\n",
    "        midpoints = {}\n",
    "        edges = [(edge[0], edge[1]) for edge in self.edges_with_weights] \n",
    "        room_centers = self.__get_room_centres()\n",
    "\n",
    "        for i, edge in enumerate(edges):\n",
    "            if i < len(room_centers):\n",
    "                midpoints[edge] = (round((room_centers[edge[0]][0] + room_centers[edge[1]][0]) / 2, 2), round((room_centers[edge[0]][1] + room_centers[edge[1]][1]) / 2, 2))\n",
    "            else:\n",
    "                midpoints[edge] = (round((room_centers[edge[0]][0] + self.entrance_door_centre.x) / 2, 2), round((room_centers[edge[0]][1] + self.entrance_door_centre.y) / 2, 2))\n",
    "        return midpoints\n",
    "    \n",
    "    def __get_shortest_paths_to_exit(self, graph: nx.Graph) -> Dict:\n",
    "            exit_node = graph.number_of_nodes() - 1\n",
    "            shortest_paths = nx.single_target_shortest_path(graph, exit_node)\n",
    "\n",
    "            def calculate_total_distance(_graph, route):\n",
    "                total_distance = 0\n",
    "                for i in range(len(route) - 1):\n",
    "                    source = route[i]\n",
    "                    target = route[i + 1]\n",
    "                    total_distance += _graph[source][target]['weight']\n",
    "\n",
    "                return total_distance\n",
    "            \n",
    "            for key in list(shortest_paths.keys()):\n",
    "                distance = calculate_total_distance(graph, shortest_paths[key])\n",
    "                shortest_paths[key] = round(distance, 2)\n",
    "            \n",
    "            return shortest_paths\n",
    "\n",
    "    def __get_exit_times(self) -> Tuple[Dict, Dict]:\n",
    "        \"\"\" Runs a monte carlo simulation on the markov chain, representing behaviour during fire. Giving predicted pre evacuation time per type of room. This function is stochastic, thus every time it is run it will return a different result\"\"\"\n",
    "\n",
    "        markov_chain = self.mrk_chain\n",
    "\n",
    "        ## Total Exit Time (Tn) = Pre-Evacuation Time (Tp) + Evacuation Time (Te)\n",
    "\n",
    "        ## Pre Evacuation Time (Tp) Variables\n",
    "\n",
    "        ## room types\n",
    "        room_types = [self.room_attributes[i]['room_type'] for i in list(self.room_attributes.keys())]\n",
    "        pre_evac_time_per_room = {i: 0.0 for i, room_type in enumerate(room_types)}\n",
    "        evac_time_per_room = {i: 0.0 for i, room_type in enumerate(room_types)}\n",
    "        \n",
    "        ## expected time if sleeping\n",
    "        pre_evac_time_sleeping = round(markov_chain.simulate_markov_chain(1, End_node),2)\n",
    "\n",
    "        ## expected time if dressing\n",
    "        pre_evac_time_dressing = round(markov_chain.simulate_markov_chain(4, End_node),2)\n",
    "\n",
    "        ## expected time if feel concern\n",
    "        pre_evac_time_concern = round(markov_chain.simulate_markov_chain(11, End_node), 2)\n",
    "\n",
    "        ## expected time if rescue attempt\n",
    "        pre_evac_time_rescue_attempt = round(markov_chain.simulate_markov_chain(14, End_node), 2)\n",
    "\n",
    "        ## Evacuation Time (Te) Variables\n",
    "        distance_to_exit = [self.room_attributes[i]['distance_to_exit'] for i in list(self.room_attributes.keys())]\n",
    "\n",
    "        ## occupant speed (assumed at 0.7 m/s)\n",
    "        ## t = d / s\n",
    "        occupant_speed = 0.7 \n",
    "\n",
    "\n",
    "        ## calculate pre-evacuation time per room, depending on prior task prediction, e.g if in bedroom, more likely to be sleeping / dressing\n",
    "\n",
    "        for i, room_type in enumerate(room_types):\n",
    "            ## add evacuation time\n",
    "            evac_time_per_room[i] = round(distance_to_exit[i] / occupant_speed)\n",
    "            ## add pre evacuation time\n",
    "            if room_type in  ['LIVING_DINING', 'LIVING_ROOM']:\n",
    "                pre_evac_time_per_room[i] = round((pre_evac_time_sleeping + pre_evac_time_concern) / 2, 2)\n",
    "            elif room_type in ['ROOM', 'BEDROOM']:\n",
    "                pre_evac_time_per_room[i] = round((pre_evac_time_sleeping + pre_evac_time_dressing) / 2, 2)\n",
    "            elif room_type == 'KITCHEN':\n",
    "                pre_evac_time_per_room[i] = pre_evac_time_rescue_attempt\n",
    "            elif room_type == 'ENTRANCE_DOOR':\n",
    "                pre_evac_time_per_room[i] = 0\n",
    "            else:\n",
    "                pre_evac_time_per_room[i] = round((pre_evac_time_concern + pre_evac_time_rescue_attempt) / 2, 2)\n",
    "\n",
    "        return pre_evac_time_per_room, evac_time_per_room\n",
    "    \n",
    "    def assign_non_normalised_label(self) -> Dict[str, int]:\n",
    "        \"\"\" Assigns raw labels to each floor plan, which are to be normalised once all labels are collected\"\"\"\n",
    "\n",
    "        apartment_id = self.apartment_id\n",
    "        graph = self.graph\n",
    "        room_types = nx.get_node_attributes(graph, 'room_type')\n",
    "        room_area = nx.get_node_attributes(graph, 'room-area')\n",
    "        kitchen_node = [key for key in list(room_types.keys()) if room_types[key] == 'KITCHEN'][0]\n",
    "        ## pre evacuation time\n",
    "        room_Tp = [x for x in nx.get_node_attributes(graph, 'time_pre_evac').values() if x != 0]\n",
    "        expected_Tp = Expected_preEvac_time\n",
    "        Tp_diff = [round(x - expected_Tp,2) for x in room_Tp]\n",
    "        Tp_average_difference = round(sum(Tp_diff) / len(Tp_diff),2)\n",
    "\n",
    "        ## evacuation time\n",
    "        room_Te = [x for x in nx.get_node_attributes(graph, 'time_evac').values() if x != 0]\n",
    "        Te_average = round(sum(room_Te) / len(room_Te),2)\n",
    "        if Te_average > 20:\n",
    "            Te_average = 20\n",
    "    \n",
    "\n",
    "        ## centrality metrics\n",
    "        room_between_cent = nx.get_node_attributes(graph, 'betweenness_centrality')\n",
    "        room_close_cent = nx.get_node_attributes(graph, 'closeness_centrality')\n",
    "        kitchen_betweenness_centrality = room_between_cent[kitchen_node]\n",
    "        kitchen_closeness_centrality = room_close_cent[kitchen_node]\n",
    "        kitchen_centrality = kitchen_closeness_centrality + kitchen_betweenness_centrality\n",
    "        if kitchen_centrality > 1.25:\n",
    "            kitchen_centrality = 1.25\n",
    "\n",
    "        floor_plan_labels = {\n",
    "            apartment_id: {\n",
    "                'Tp_average_difference': Tp_average_difference,\n",
    "                'Te_average': Te_average,\n",
    "                'kitchen_centrality': kitchen_centrality\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return floor_plan_labels\n",
    "\n",
    "    def save_training_image(self, width_pixels: float, height_pixels: float, dpi: int, transparent_background: bool, subfolder: str) -> None:\n",
    "        plan_id = self.plan_id\n",
    "        apartment_id = self.apartment_id\n",
    "\n",
    "        os.makedirs(subfolder, exist_ok=True)\n",
    "        filepath = os.path.join(subfolder, f\"{apartment_id}.png\")  # Include file extension and possibly more info\n",
    "        \n",
    "        try:\n",
    "            colours = self.__give_colours()\n",
    "            polygons = shapely.wkt.loads(self.plans[plan_id][apartment_id]['geometries_dict'])\n",
    "        except Exception as e:\n",
    "            # print(f\"Error loading data: {e}\")\n",
    "            return\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(width_pixels / dpi, height_pixels / dpi))\n",
    "        \n",
    "        try:\n",
    "            for polygon, colour in zip(polygons, colours):\n",
    "                x, y = polygon.exterior.xy\n",
    "                ax.fill(x, y, color=colour)\n",
    "            \n",
    "            ax.set_aspect('equal', 'box')\n",
    "            ax.axis('off')\n",
    "            plt.savefig(filepath, dpi=dpi, transparent=transparent_background)\n",
    "            plt.close(fig)  # Close the figure to free up memory\n",
    "            # print(f\"Image saved to {filepath}\")\n",
    "        except Exception as e:\n",
    "            # print(f\"Error saving image: {e}\")\n",
    "            if os.path.exists(filepath):\n",
    "                os.remove(filepath)  # Remove the file if saving fails to prevent incomplete files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plan_graphs(plans, plan_ids, apartment_ids):\n",
    "    labels = {}\n",
    "    \n",
    "    for i, plan_id in enumerate(plan_ids):\n",
    "        for apartment_id in apartment_ids[plan_id]:\n",
    "            try:\n",
    "                plan = Plan(plan_id, apartment_id, plans, behaviour_class, room_weights)\n",
    "\n",
    "                label = plan.assign_non_normalised_label()\n",
    "                plan.save_training_image(224,224,300,True,'raw_saved_images') ## takes around 12-14 minutes to run for all plans\n",
    "                labels[apartment_id] = list(label.values())[0]\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plans_dataset = make_plan_graphs(plans, plan_ids,apartment_ids)\n",
    "\n",
    "# print(plans_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_labels(raw_labels):\n",
    "    tp_avg_diff = []\n",
    "    te_avg = []\n",
    "    kitchen_cent = []\n",
    "    normalised_labels_dict = {}\n",
    "\n",
    "    for apartment_id in list(raw_labels.keys()):\n",
    "        tp_avg_diff.append(raw_labels[apartment_id]['Tp_average_difference'])\n",
    "        te_avg.append(raw_labels[apartment_id]['Te_average'])\n",
    "        kitchen_cent.append(raw_labels[apartment_id]['kitchen_centrality'])\n",
    "    def normalize_list(lst):\n",
    "        min_val = min(lst)\n",
    "        max_val = max(lst)\n",
    "        range_val = max_val - min_val\n",
    "        normalized_lst = [(x - min_val) / range_val for x in lst]\n",
    "        return normalized_lst\n",
    "    def z_score_normalization(values):\n",
    "        \"\"\"\n",
    "        Normalize a list of values using Z-score normalization.\n",
    "\n",
    "        Args:\n",
    "            values (list): A list of numeric values.\n",
    "\n",
    "        Returns:\n",
    "            list: Normalized values using Z-score normalization.\n",
    "        \"\"\"\n",
    "        # Convert the values to a NumPy array for easy mathematical operations\n",
    "        values_array = np.array(values)\n",
    "        \n",
    "        # Calculate the mean and standard deviation of the values\n",
    "        mean = np.mean(values_array)\n",
    "        std_dev = np.std(values_array)\n",
    "        \n",
    "        # Normalize the values using Z-score normalization\n",
    "        normalized_values = (values_array - mean) / std_dev\n",
    "        \n",
    "        return normalized_values.tolist()\n",
    "    \n",
    "    norm_tp_avg_diff = normalize_list(z_score_normalization(tp_avg_diff))\n",
    "    norm_te_avg = normalize_list(z_score_normalization(te_avg))\n",
    "    norm_kitchen_cent = normalize_list(z_score_normalization(kitchen_cent))\n",
    "\n",
    "    def average_lists(list1, list2, list3):\n",
    "        combined_list = []\n",
    "        for elem1, elem2, elem3 in zip(list1, list2, list3):\n",
    "            average = (elem1 + elem2 + elem3) / 3\n",
    "            combined_list.append(average)\n",
    "        n_v =  normalize_list(combined_list)\n",
    "        return n_v\n",
    "    \n",
    "    normalised_labels = average_lists(norm_tp_avg_diff, norm_te_avg, norm_kitchen_cent)\n",
    "    for i, apartment_id in enumerate(list(raw_labels.keys())):\n",
    "        normalised_labels_dict[apartment_id] = round(normalised_labels[i],1)\n",
    "    return normalised_labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised_Labels = normalise_labels(plans_dataset)\n",
    "# print(Normalised_Labels)\n",
    "# Plotting the histogram\n",
    "# plt.hist(Normalised_Labels, bins=10, color='blue', edgecolor='black')\n",
    "\n",
    "# # Adding labels and title\n",
    "# plt.xlabel('Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Histogram of List of Numbers')\n",
    "\n",
    "# # Displaying the plot\n",
    "# plt.show()\n",
    "\n",
    "# with open('training_plan_labels.json', 'w') as json_file:\n",
    "#     json.dump(Normalised_Labels, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorder images to train and test datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load dataset labels from json to python dictionary\n",
    "\n",
    "with open('training_plan_labels.json', 'r') as file:\n",
    "    labels = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.4, 0.5, 0.6, 0.2, 0.3, 0.7, 0.1, 0.0, 0.8, 0.9, 1.0}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = (set(labels.values()))\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_foldername_mapping = {\n",
    "    0.0: 'score0',\n",
    "    0.1: 'score1',\n",
    "    0.2: 'score2',\n",
    "    0.3: 'score3',\n",
    "    0.4: 'score4',\n",
    "    0.5: 'score5',\n",
    "    0.6: 'score6',\n",
    "    0.7: 'score7',\n",
    "    0.8: 'score8',\n",
    "    0.9: 'score9',\n",
    "    1.0: 'score10'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_images_dataset(source_folder = 'raw_saved_images', train_folder = 'dataset_images/train', test_folder = 'dataset_images/test', training_size_percentage = 0.7) -> None:\n",
    "\n",
    "    \"\"\" Moves images from raw folder to split into training and testing sub sets and also assign labels from dataset_labels.json\"\"\"\n",
    "\n",
    "    # List all images\n",
    "    images = os.listdir(source_folder)\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Calculate the split\n",
    "    split_index = int(training_size_percentage * len(images))\n",
    "\n",
    "    # Split into train and test sets\n",
    "    train_images = images[:split_index]\n",
    "    test_images = images[split_index:]\n",
    "\n",
    "    # Move images to train folder\n",
    "    for img in train_images:\n",
    "        src_path = os.path.join(source_folder, img)\n",
    "        dest_path = os.path.join(train_folder, img)\n",
    "        shutil.move(src_path, dest_path, copy_function = shutil.copytree)\n",
    "    # Move images to test folder\n",
    "    for img in test_images:\n",
    "        src_path = os.path.join(source_folder, img)\n",
    "        dest_path = os.path.join(test_folder, img)\n",
    "        shutil.move(src_path, dest_path)\n",
    "\n",
    "    print(\"Dataset split completed.\")\n",
    "\n",
    "# split_images_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_to_foldername_mapping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21morder_images_dataset_to_classes\u001b[39m(train_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_images/train\u001b[39m\u001b[38;5;124m'\u001b[39m, test_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_images/test\u001b[39m\u001b[38;5;124m'\u001b[39m, class_mapping \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_to_foldername_mapping\u001b[49m):\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# create class folders if they dont exist\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m class_mapping\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      5\u001b[0m         class_folder \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[1;31mNameError\u001b[0m: name 'label_to_foldername_mapping' is not defined"
     ]
    }
   ],
   "source": [
    "def order_images_dataset_to_classes(train_folder = 'dataset_images/train', test_folder = 'dataset_images/test', class_mapping = label_to_foldername_mapping):\n",
    "\n",
    "    # create class folders if they dont exist\n",
    "    for key, value in class_mapping.items():\n",
    "        class_folder = value\n",
    "        train_destination_folder = train_folder +  '/' + class_folder\n",
    "        test_destination_folder = test_folder + '/' + class_folder\n",
    "        print(train_destination_folder)\n",
    "        if not os.path.exists(train_destination_folder):\n",
    "            os.makedirs(train_destination_folder)\n",
    "        if not os.path.exists(test_destination_folder):\n",
    "            os.makedirs(test_destination_folder)\n",
    "\n",
    "    def move_to_class_folders(source_folder, class_mapping):\n",
    "\n",
    "        images = os.listdir(source_folder)\n",
    "        for img in images:\n",
    "            src_path = os.path.join(source_folder, img)\n",
    "            labels_key = os.path.splitext(os.path.basename(src_path))[0]\n",
    "            label = labels[labels_key]\n",
    "            class_folder = class_mapping[label]\n",
    "\n",
    "            dest_path = os.path.join(source_folder, class_folder, img)\n",
    "            print(dest_path)\n",
    "            shutil.move(src_path, dest_path)\n",
    "\n",
    "    # move_to_class_folders(train_folder, class_mapping)\n",
    "    # move_to_class_folders(test_folder, class_mapping)\n",
    "\n",
    "# order_images_dataset_to_classes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
